<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>Computer Vision Lecture 1</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	text-indent: -1.7em;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-opaquegray { background-color: rgba(255, 255, 255, 0.0375); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(253, 236, 200, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="bb8f1314-6ebd-4a32-bc6d-9fb4fc6c8bce" class="page sans"><header><h1 class="page-title">Computer Vision Lecture 1</h1><table class="properties"><tbody><tr class="property-row property-row-date"><th><span class="icon property-icon"><svg viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.45);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesDate"><path d="M3.29688 14.4561H12.7031C14.1797 14.4561 14.9453 13.6904 14.9453 12.2344V3.91504C14.9453 2.45215 14.1797 1.69336 12.7031 1.69336H3.29688C1.82031 1.69336 1.05469 2.45215 1.05469 3.91504V12.2344C1.05469 13.6973 1.82031 14.4561 3.29688 14.4561ZM3.27637 13.1162C2.70898 13.1162 2.39453 12.8154 2.39453 12.2207V5.9043C2.39453 5.30273 2.70898 5.00879 3.27637 5.00879H12.71C13.2842 5.00879 13.6055 5.30273 13.6055 5.9043V12.2207C13.6055 12.8154 13.2842 13.1162 12.71 13.1162H3.27637ZM6.68066 7.38086H7.08398C7.33008 7.38086 7.41211 7.30566 7.41211 7.05957V6.66309C7.41211 6.41699 7.33008 6.3418 7.08398 6.3418H6.68066C6.44141 6.3418 6.35938 6.41699 6.35938 6.66309V7.05957C6.35938 7.30566 6.44141 7.38086 6.68066 7.38086ZM8.92285 7.38086H9.31934C9.56543 7.38086 9.64746 7.30566 9.64746 7.05957V6.66309C9.64746 6.41699 9.56543 6.3418 9.31934 6.3418H8.92285C8.67676 6.3418 8.59473 6.41699 8.59473 6.66309V7.05957C8.59473 7.30566 8.67676 7.38086 8.92285 7.38086ZM11.1582 7.38086H11.5547C11.8008 7.38086 11.8828 7.30566 11.8828 7.05957V6.66309C11.8828 6.41699 11.8008 6.3418 11.5547 6.3418H11.1582C10.9121 6.3418 10.8301 6.41699 10.8301 6.66309V7.05957C10.8301 7.30566 10.9121 7.38086 11.1582 7.38086ZM4.44531 9.58203H4.84863C5.09473 9.58203 5.17676 9.50684 5.17676 9.26074V8.86426C5.17676 8.61816 5.09473 8.54297 4.84863 8.54297H4.44531C4.20605 8.54297 4.12402 8.61816 4.12402 8.86426V9.26074C4.12402 9.50684 4.20605 9.58203 4.44531 9.58203ZM6.68066 9.58203H7.08398C7.33008 9.58203 7.41211 9.50684 7.41211 9.26074V8.86426C7.41211 8.61816 7.33008 8.54297 7.08398 8.54297H6.68066C6.44141 8.54297 6.35938 8.61816 6.35938 8.86426V9.26074C6.35938 9.50684 6.44141 9.58203 6.68066 9.58203ZM8.92285 9.58203H9.31934C9.56543 9.58203 9.64746 9.50684 9.64746 9.26074V8.86426C9.64746 8.61816 9.56543 8.54297 9.31934 8.54297H8.92285C8.67676 8.54297 8.59473 8.61816 8.59473 8.86426V9.26074C8.59473 9.50684 8.67676 9.58203 8.92285 9.58203ZM11.1582 9.58203H11.5547C11.8008 9.58203 11.8828 9.50684 11.8828 9.26074V8.86426C11.8828 8.61816 11.8008 8.54297 11.5547 8.54297H11.1582C10.9121 8.54297 10.8301 8.61816 10.8301 8.86426V9.26074C10.8301 9.50684 10.9121 9.58203 11.1582 9.58203ZM4.44531 11.7832H4.84863C5.09473 11.7832 5.17676 11.708 5.17676 11.4619V11.0654C5.17676 10.8193 5.09473 10.7441 4.84863 10.7441H4.44531C4.20605 10.7441 4.12402 10.8193 4.12402 11.0654V11.4619C4.12402 11.708 4.20605 11.7832 4.44531 11.7832ZM6.68066 11.7832H7.08398C7.33008 11.7832 7.41211 11.708 7.41211 11.4619V11.0654C7.41211 10.8193 7.33008 10.7441 7.08398 10.7441H6.68066C6.44141 10.7441 6.35938 10.8193 6.35938 11.0654V11.4619C6.35938 11.708 6.44141 11.7832 6.68066 11.7832ZM8.92285 11.7832H9.31934C9.56543 11.7832 9.64746 11.708 9.64746 11.4619V11.0654C9.64746 10.8193 9.56543 10.7441 9.31934 10.7441H8.92285C8.67676 10.7441 8.59473 10.8193 8.59473 11.0654V11.4619C8.59473 11.708 8.67676 11.7832 8.92285 11.7832Z"></path></svg></span>Date</th><td><time>@October 1, 2022</time></td></tr><tr class="property-row property-row-number"><th><span class="icon property-icon"><svg viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.45);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesNumber"><path d="M2.4834 10.9902H4.33594L3.75488 13.8887C3.74121 13.9639 3.72754 14.0664 3.72754 14.1416C3.72754 14.5381 3.99414 14.7637 4.39746 14.7637C4.81445 14.7637 5.09473 14.5449 5.18359 14.1143L5.80566 10.9902H8.79297L8.21191 13.8887C8.19824 13.9639 8.18457 14.0664 8.18457 14.1416C8.18457 14.5381 8.45117 14.7637 8.85449 14.7637C9.27148 14.7637 9.55176 14.5449 9.63379 14.1143L10.2627 10.9902H12.4502C12.9287 10.9902 13.2432 10.6758 13.2432 10.2109C13.2432 9.8418 12.9902 9.56836 12.6006 9.56836H10.5498L11.2129 6.28711H13.3662C13.8379 6.28711 14.1523 5.96582 14.1523 5.50098C14.1523 5.13184 13.9062 4.8584 13.5098 4.8584H11.5L12.0195 2.27441C12.0264 2.21973 12.0469 2.11035 12.0469 2.01465C12.0469 1.625 11.7666 1.39258 11.3633 1.39258C10.9053 1.39258 10.6797 1.63867 10.5977 2.05566L10.0303 4.8584H7.04297L7.5625 2.27441C7.57617 2.21973 7.58984 2.11035 7.58984 2.01465C7.58984 1.625 7.30957 1.39258 6.91309 1.39258C6.44824 1.39258 6.21582 1.63867 6.13379 2.05566L5.57324 4.8584H3.54297C3.06445 4.8584 2.75 5.18652 2.75 5.65137C2.75 6.03418 3.00293 6.28711 3.39258 6.28711H5.28613L4.62305 9.56836H2.63379C2.15527 9.56836 1.84082 9.89648 1.84082 10.3613C1.84082 10.7373 2.09375 10.9902 2.4834 10.9902ZM6.09277 9.56836L6.75586 6.28711H9.74316L9.08008 9.56836H6.09277Z"></path></svg></span>Number</th><td>1</td></tr><tr class="property-row property-row-text"><th><span class="icon property-icon"><svg viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.45);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesText"><path d="M1.56738 3.25879H14.4258C14.7676 3.25879 15.0479 2.97852 15.0479 2.63672C15.0479 2.29492 14.7744 2.02148 14.4258 2.02148H1.56738C1.21875 2.02148 0.952148 2.29492 0.952148 2.63672C0.952148 2.97852 1.22559 3.25879 1.56738 3.25879ZM1.56738 6.84082H14.4258C14.7676 6.84082 15.0479 6.56055 15.0479 6.21875C15.0479 5.87695 14.7744 5.60352 14.4258 5.60352H1.56738C1.21875 5.60352 0.952148 5.87695 0.952148 6.21875C0.952148 6.56055 1.22559 6.84082 1.56738 6.84082ZM1.56738 10.4229H14.4258C14.7676 10.4229 15.0479 10.1426 15.0479 9.80078C15.0479 9.45898 14.7744 9.18555 14.4258 9.18555H1.56738C1.21875 9.18555 0.952148 9.45898 0.952148 9.80078C0.952148 10.1426 1.22559 10.4229 1.56738 10.4229ZM1.56738 14.0049H8.75879C9.10059 14.0049 9.38086 13.7246 9.38086 13.3828C9.38086 13.041 9.10742 12.7676 8.75879 12.7676H1.56738C1.21875 12.7676 0.952148 13.041 0.952148 13.3828C0.952148 13.7246 1.22559 14.0049 1.56738 14.0049Z"></path></svg></span>Topics</th><td>Introduction, image filtering</td></tr><tr class="property-row property-row-select"><th><span class="icon property-icon"><svg viewBox="0 0 16 16" style="width:14px;height:14px;display:block;fill:rgba(55, 53, 47, 0.45);flex-shrink:0;-webkit-backface-visibility:hidden" class="typesSelect"><path d="M8 15.126C11.8623 15.126 15.0615 11.9336 15.0615 8.06445C15.0615 4.20215 11.8623 1.00293 7.99316 1.00293C4.13086 1.00293 0.938477 4.20215 0.938477 8.06445C0.938477 11.9336 4.1377 15.126 8 15.126ZM8 13.7383C4.85547 13.7383 2.33301 11.209 2.33301 8.06445C2.33301 4.91992 4.84863 2.39746 7.99316 2.39746C11.1377 2.39746 13.6738 4.91992 13.6738 8.06445C13.6738 11.209 11.1445 13.7383 8 13.7383ZM7.62402 10.6348C7.79492 10.915 8.20508 10.9287 8.37598 10.6348L10.666 6.73145C10.8574 6.41016 10.7002 6.04102 10.3652 6.04102H5.62793C5.29297 6.04102 5.14941 6.43066 5.32031 6.73145L7.62402 10.6348Z"></path></svg></span>Type</th><td><span class="selected-value select-value-color-orange">Lecture</span></td></tr></tbody></table></header><div class="page-body"><nav id="b5540a13-3e2e-4fa9-b964-ced9ffec24f2" class="block-color-gray table_of_contents"><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#2e17fdd7-8589-492a-a89e-d6bbd1bb1ba4">Introduction</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#92b172ec-6531-457b-a75f-6a9880fa5983">Perception Pipeline</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#22d825d0-24d2-4907-8384-2e027ead74c5">Some Applications</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#6a980357-00b0-450a-b3aa-63c91cb88e88">CV as a rising industry</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#732c61fe-b1e9-45a7-9515-3a426df254b7">Topics to be covered in this course</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#7b89b305-39f9-4aea-b676-f74d260a912b">Image Filtering</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#75059e16-49a4-40ce-a10a-8be5241d714b">Transformations</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#95ea0451-7f97-4cdc-b745-5877427324c0">Filtering</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#66cb33db-ca3f-4a6f-a7e1-d4600a847c1c">Warping</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#f6ae3c4e-eec3-49e9-8734-124884068cd2">Point Operation</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#b02801be-b3bc-47fa-9c98-b4257700b17f">Filtering (Neighborhood Operation)</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#2e616c57-4066-4386-924a-b0e3e35f6135">Point Processing </a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#efb995a9-3bfe-49c8-a10e-ebc511986f45">Linear shift-invariant image filtering</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#cb6556d9-e6da-42e9-8638-d81a9c4c6c69">Convolution and Correlation</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#3ab4eca5-df76-4dab-a534-89e66f1a7fa4">Box Filter</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#eecc9465-cf78-4254-8af3-bb63f1111d7a">Separable Filters</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#2c3bbb00-4462-42bd-9175-6b1f2173dde9">The Gaussian Filter</a></div><div class="table_of_contents-item table_of_contents-indent-2"><a class="table_of_contents-link" href="#dbd6c75a-4227-46a3-8c21-baca8dfbed47">Pascal’s Triangle </a></div></nav><h1 id="2e17fdd7-8589-492a-a89e-d6bbd1bb1ba4" class="">Introduction</h1><p id="4b05c031-b9a3-4c87-978e-76f23b28ff4a" class="">The difference in <strong>classical computer vision </strong>vs <strong>deep learning</strong> lies in the way feature extrtaction is done. In the former, features extraction is done manually, and the engineer has the task of selecting which features are of interest, whereas in the latter deep learning is an end-to-end solution that learns the feature extraction process.<div class="indented"><figure id="b3743f9a-d86c-4dc0-ba96-074f8ad16306" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled.png"><img style="width:1560px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled.png"/></a><figcaption>(<a href="https://www.mvtec.com/technologies/deep-learning/classic-machine-vision-vs-deep-learning">Source</a>)</figcaption></figure></div></p><ul id="4780814e-b84d-4fb9-9a40-221facb79e83" class="bulleted-list"><li style="list-style-type:disc"><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>What is vision? </strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>It is the ability to know what is where by looking 👀<ul id="a25ee126-827a-4be5-9f39-863f45d018bf" class="bulleted-list"><li style="list-style-type:circle">The act of opening your eyes prepares you to perceive your environment</li></ul><ul id="dda6ae13-c294-47ee-aa2d-572464b51ad8" class="bulleted-list"><li style="list-style-type:circle">To start washing your face, you first start processing your environment</li></ul><figure class="block-color-brown_background callout" style="white-space:pre-wrap;display:flex" id="b736c7cd-eb61-442a-9061-749d51746433"><div style="font-size:1.5em"><span class="icon">👁️</span></div><div style="width:100%">As humans, we perceive the three-dimensional structure of the world around us with apparent ease. Think of how vivid the three-dimensional percept is when you look at a vase of flowers sitting on the table next to you. You can tell the shape and translucency of each petal through the subtle patterns of light and shading that play across its surface and effortlessly segment each flower from the background of the scene. Looking at a framed group portrait, you can easily count (and name) all of the people in the picture and even guess at their emotions from their facial appearance. Perceptual psychologists have spent decades trying to understand how the visual system works and, even though they can devise optical illusions to tease apart some of its principles, a complete solution to this puzzle remains elusive<figure id="5c3ee6fc-26e4-4795-b581-daca2229d582" class="image" style="text-align:center"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%201.png"><img style="width:288px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%201.png"/></a></figure></div></figure></li></ul><ul id="30eee726-ca9c-42f7-b777-85c2251db1c7" class="bulleted-list"><li style="list-style-type:disc">The difference between computer vision and human vision lies in the presentation of an image: <ul id="e2daab4e-9746-4af2-be94-b0c6f5c46b94" class="bulleted-list"><li style="list-style-type:circle">A computer sees a matrix of 0s and 1s with a dimension</li></ul><ul id="4fecf46b-9fb6-4cea-9c46-5f7587f724d6" class="bulleted-list"><li style="list-style-type:circle">A human sees an image as it is</li></ul></li></ul><div id="9a36cc4b-6ba5-46b9-af37-61ea48f39179" class="column-list"><div id="3dd92abc-e689-43b3-8e92-f5d27a6bf934" style="width:43.75%" class="column"><figure id="4792f47a-3c02-49f0-adb9-9f93f8e83486" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%202.png"><img style="width:288px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%202.png"/></a></figure><p id="c291a63a-14c5-419b-afe2-99c94e89a9b3" class="">
</p></div><div id="98db1932-6c50-4b4d-bede-49eeadea90a7" style="width:56.25%" class="column"><figure id="207a8e02-8548-4c53-a234-3e1ceffa5ab2" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%203.png"><img style="width:432px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%203.png"/></a></figure></div></div><ul id="ec958de1-584b-4bc2-9143-ef5a9d266793" class="bulleted-list"><li style="list-style-type:disc">Computer Representation<ul id="d88ebfe0-6e79-4ff8-ab3f-a27105b3af92" class="bulleted-list"><li style="list-style-type:circle"><strong><strong><strong><strong><strong><strong><strong>The dimension </strong></strong></strong></strong></strong></strong></strong>represents the number of <strong><strong><strong>pixels </strong></strong></strong>in an image.</li></ul><ul id="2ce675b4-52b9-461b-b8a3-3c3b4ccab6db" class="bulleted-list"><li style="list-style-type:circle">Each pixel has an intensity value between 0 and 255</li></ul><ul id="e2068fbb-d367-4ee2-a697-9eaa5e42603d" class="bulleted-list"><li style="list-style-type:circle">For RGB pictures, there are 3 channels, one for each of the primary colors</li></ul></li></ul><ul id="d384f6e0-c5d8-4d06-9a10-1c878b371e21" class="bulleted-list"><li style="list-style-type:disc">Algorithms that exist to process and map the two presentations are not trivial, as the difference between them is far too great</li></ul><ul id="12fd9c8d-647d-4353-a803-edf735111816" class="bulleted-list"><li style="list-style-type:disc">Computer vision can easily surpass human vision, in which case it can be called <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Superhuman Vision. </strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>There are many reasons why computer vision can be more powerful:<ul id="6d055301-73d8-41ca-ba65-6f15a22a47a9" class="bulleted-list"><li style="list-style-type:circle">Humans can only see the visible light spectrum, while computers can see other spectrums such as infra-red and ultra-violet</li></ul><ul id="fc0ae298-61b6-458e-a855-5ff4d18530f3" class="bulleted-list"><li style="list-style-type:circle">Humans need light to see; they only see as a result of the existence of a light source</li></ul><ul id="a7d9524e-acfa-40a0-9888-516e910046d6" class="bulleted-list"><li style="list-style-type:circle">Human vision is subject to illusions, where it over-compensates for unclear visuals<figure class="block-color-brown_background callout" style="white-space:pre-wrap;display:flex" id="17382aaf-64aa-4384-84dc-cb9801975f62"><div style="font-size:1.5em"><span class="icon">👁️</span></div><div style="width:100%">The classic Muller-Lyer illusion, where the length of the two horizontal lines appear different, probably due to the imagined perspective effects.</div></figure><figure id="075ec315-75b4-4e26-bbc6-d4d3852624c7" class="image" style="text-align:center"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%204.png"><img style="width:240px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%204.png"/></a></figure></li></ul><ul id="32e6e98b-629a-4f80-906b-789343aebfc8" class="bulleted-list"><li style="list-style-type:circle">Computer vision is more precise</li></ul></li></ul><h3 id="92b172ec-6531-457b-a75f-6a9880fa5983" class="">Perception Pipeline</h3><div id="a0e46715-c45a-40a9-8f16-63abb19d9904" class="column-list"><div id="dad57b43-bcd9-4f63-8898-9faef204ddf8" style="width:50.000000000000014%" class="column"><ul id="0df8e407-5a2c-4c7f-91b2-9923b8014a86" class="bulleted-list"><li style="list-style-type:disc">By fancy maths, we can define so many models and techniques, each could take a whole class to be taught.</li></ul><ul id="0c69a4d2-6f3c-415e-b701-eedccadbcce7" class="bulleted-list"><li style="list-style-type:disc">A popular problem in computer vision is <strong><strong><strong><strong><strong><strong><strong>semantic segmentation</strong></strong></strong></strong></strong></strong></strong></li></ul><ul id="f1bec2ae-11a3-459f-b0c4-105121effc4a" class="bulleted-list"><li style="list-style-type:disc">Our steps usually include first defining a problem presentation then carrying our a model</li></ul></div><div id="da26b58a-5284-4944-ac9b-9443c634d676" style="width:50.000000000000014%" class="column"><figure id="e5714459-db4e-40e6-8ea3-461ed81ee4f3" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%205.png"><img style="width:411px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%205.png"/></a></figure></div></div><ul id="3c8242eb-4372-4730-93db-6e74b026dafb" class="bulleted-list"><li style="list-style-type:disc">It is important to note that <strong><strong><strong><strong><strong><strong><strong><strong><strong>most problems are not solvable by CV. </strong></strong></strong></strong></strong></strong></strong></strong></strong>Only a few problems have been tackled successfully to reach satisfiable accuracies:<ul id="b9f10d2a-e737-4f6f-a331-384b2763549e" class="bulleted-list"><li style="list-style-type:circle">Fingerprint detection (almost a 100% accuracy)</li></ul><ul id="03c0f60b-5656-4d21-80e0-e73ada99a0e6" class="bulleted-list"><li style="list-style-type:circle">Handwriting<p id="ebbf76c2-6d22-42c6-b83d-2a65de35220a" class="">And more..</p></li></ul></li></ul><ul id="16bfd0c3-a673-4295-b677-1eb768271849" class="bulleted-list"><li style="list-style-type:disc">For a problem to be CV-solvable, certain conditions and assumptions are necessary.</li></ul><h3 id="22d825d0-24d2-4907-8384-2e027ead74c5" class="">Some Applications</h3><ul id="6db00061-5109-4c15-b8c5-044d85907e04" class="bulleted-list"><li style="list-style-type:disc">Optical character recognition (OCR)</li></ul><ul id="b5dd4f39-651e-427b-8f35-cc5d91a03ae6" class="bulleted-list"><li style="list-style-type:disc">Machine automated visiual inspection</li></ul><ul id="ced369a8-fbd3-4ca3-88d2-d7b446712217" class="bulleted-list"><li style="list-style-type:disc">Retail: object recognition for automated</li></ul><ul id="ede24f1d-600f-4ab8-bfeb-0c230dcf3050" class="bulleted-list"><li style="list-style-type:disc">3D model building (photogrammetry)</li></ul><ul id="1f65bd14-b910-4169-a285-3085d6913e6d" class="bulleted-list"><li style="list-style-type:disc">Medical imaging</li></ul><ul id="055ec933-7200-493f-86b4-69687b88a06c" class="bulleted-list"><li style="list-style-type:disc">Automotive safety</li></ul><ul id="d30d1728-42ba-4223-9a84-8dd916dcdf98" class="bulleted-list"><li style="list-style-type:disc">Motion capture</li></ul><ul id="11d1241f-6c67-4eec-8665-4b5e16333d93" class="bulleted-list"><li style="list-style-type:disc">Surveillance</li></ul><ul id="8185e7bc-5518-4cd2-81c3-9fb2c3130b48" class="bulleted-list"><li style="list-style-type:disc">Fingerprint recognition and biometrics</li></ul><ul id="bfffef20-2aeb-4067-8dc4-83fe8760e9f2" class="bulleted-list"><li style="list-style-type:disc">Object Recognition</li></ul><ul id="538819a3-d025-488d-a199-3728af1c124d" class="bulleted-list"><li style="list-style-type:disc">Face detection (age, smile, expression, identity)</li></ul><ul id="3574558b-30bb-4386-8870-c9e06c003513" class="bulleted-list"><li style="list-style-type:disc">Plant and bird ID (Merlin bird app by Cornell lab is great for bird species identification; plant identification can also encompass bug and disease detection)</li></ul><ul id="4a110e4c-e0c3-491a-bd7d-bd4fefcc6422" class="bulleted-list"><li style="list-style-type:disc">Self-driving cars:<ul id="4a1706bc-15db-40b5-ba9e-67e68927fb80" class="bulleted-list"><li style="list-style-type:circle">night vision</li></ul><ul id="157487fc-149e-4600-8b6f-2df27c725e35" class="bulleted-list"><li style="list-style-type:circle">around view camera (these compensate for the driver’s blind zone, which is in cone shape behind the driver)</li></ul><figure id="69970029-099d-4d46-8bf8-cd7e7690c96a"><div class="source"><a href="https://youtu.be/xqWkJJOcU4g">https://youtu.be/xqWkJJOcU4g</a></div></figure></li></ul><div id="dc7bf317-befe-4642-ba2e-d73c2d36b607" class="column-list"><div id="cc219b45-57c5-4eba-91ca-dddd51c95b33" style="width:62.5%" class="column"><figure id="74c97b0e-f3da-440b-b117-3094871b3e21" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%206.png"><img style="width:384px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%206.png"/></a></figure></div><div id="a7e99637-7b60-47a1-ae70-b3c75ed64d12" style="width:37.49999999999999%" class="column"><p id="0b501448-9978-43ca-a324-cefb1d34ddaf" class=""><em>Some industrial applications of computer vision: (a) optical character recognition (OCR) </em><em><a href="http://yann/">http://yann</a></em><em>.
</em><em><a href="http://lecun.com/exdb/lenet/">lecun.com/exdb/lenet/</a></em><em>; (b) mechanical inspection </em><em><a href="http://www.cognitens.com/">http://www.cognitens.com/</a></em><em>; (c) retail </em><em><a href="http://www.evoretail.com/">http://www.evoretail.com/</a></em><em>; (d) medical imaging </em><em><a href="http://www.clarontech.com/">http://www.clarontech.com/</a></em><em>; (e) automotive safety </em><em><a href="http://www.mobileye.com/">http://www.mobileye.com/</a></em><em>; (f) surveillance and traffic monitoring </em><em><a href="http://www.honeywellvideo.com/">http://www.honeywellvideo.com/</a></em><em>, courtesy of Honeywell International Inc.</em></p></div></div><div id="c2e8a01c-7f59-40a9-87d1-190376a91530" class="column-list"><div id="189a69a3-89ad-499f-b448-373edda7e7b7" style="width:62.5%" class="column"><figure id="8b9127e1-d72e-41fe-af0e-c86a4d336cb5" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%207.png"><img style="width:775px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%207.png"/></a></figure><p id="a6f29791-d530-429a-9fe7-800100d002c5" class="">
</p></div><div id="369aa14c-8a22-44d0-9ce4-311fa2398c50" style="width:37.50000000000001%" class="column"><p id="cba9bfb8-94e9-4206-ae63-e4ebe8fe7935" class=""><em>Some consumer applications of computer vision: (a) image stitching: merging different views
(Szeliski and Shum 1997) c 1997 ACM; (b) exposure bracketing: merging different exposures; (c) morphing: blending between two photographs (Gomes, Darsa, Costa et al. 1999) c 1999 Morgan Kaufmann; (d) turning a collection of photographs into a 3D model (Sinha, Steedly, Szeliski et al. 2008) c 2008 ACM</em></p></div></div><h3 id="6a980357-00b0-450a-b3aa-63c91cb88e88" class="">CV as a rising industry</h3><ul id="3cb953de-d985-4b02-8227-b2ddb53e9493" class="bulleted-list"><li style="list-style-type:disc">The industry is aggressively hiring CV faculty members from universities</li></ul><ul id="b97e5a47-a2f9-4211-8e7f-40607028e843" class="bulleted-list"><li style="list-style-type:disc">The Conference on Computer Vision and Pattern Recognition (CVPR) is an annual conference on computer vision and pattern recognition, which is regarded as one of the most important conferences in its field.</li></ul><figure id="68e508c6-8a02-4bae-a8fb-da036711c2ce" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%208.png"><img style="width:3360px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%208.png"/></a></figure><figure id="d4feadc7-ff34-4a1f-bb8f-43db52228b17" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%209.png"><img style="width:532px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%209.png"/></a></figure><h2 id="732c61fe-b1e9-45a7-9515-3a426df254b7" class="">Topics to be covered in this course</h2><ul id="0ba01004-3030-4fda-b545-169f9bbb672a" class="bulleted-list"><li style="list-style-type:disc">Image processing (assignment 1)<ul id="dbde3b2b-b5a3-424c-a194-95e71e287a20" class="bulleted-list"><li style="list-style-type:circle">Filteting</li></ul><ul id="236ad823-42e0-4e75-bac9-67a72ae30754" class="bulleted-list"><li style="list-style-type:circle">pyramids</li></ul></li></ul><ul id="fcc78dcd-ba57-4abe-a6f4-898e8531728e" class="bulleted-list"><li style="list-style-type:disc">Feature detection (assignment 2)</li></ul><ul id="b61f7a76-8d0a-4a1d-ab65-a806615c693b" class="bulleted-list"><li style="list-style-type:disc">Transformation (assignment 3)</li></ul><ul id="36999cbe-8d51-45ba-a034-f1df98e30150" class="bulleted-list"><li style="list-style-type:disc">Objects/faces learning (1-2 lectures)</li></ul><ul id="ba2ae466-2dc5-45f9-84c4-8216d3b9363e" class="bulleted-list"><li style="list-style-type:disc">Videos (assignment 4)</li></ul><h1 id="7b89b305-39f9-4aea-b676-f74d260a912b" class="">Image Filtering</h1><p id="970dd744-b411-4ba6-bf25-ecb696b2cc39" class=""><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>What is an image? </strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>An image is comprised of <strong>pixels </strong>arranged in a 2D matrix. An image typically has 3 of these 2D matrices, each representing one of the primary colors, red, green, or blue, otherwise called <strong>channels</strong>. A combination of those pixels and channels forms the image.</p><div id="1ed85142-3df5-4161-b5a7-1673b8e7fc04" class="column-list"><div id="9c7024ff-52a3-4ca4-8d68-207f865b111d" style="width:50%" class="column"><p id="dad1cbe6-2767-467a-bd83-18dac1541d61" class="">If you zoom in on an image, you will see a 3D <strong><strong><strong><strong><strong><strong><strong><strong>tensor. </strong></strong></strong></strong></strong></strong></strong></strong>A tensor is the generalization of vectors and matrices. While vectors are 1D, matrices are 2D, tensors are 3D and up.</p><p id="34c7b1f7-1efa-4d4e-acbf-c631d7b25d6e" class="">
</p></div><div id="7c60f34f-0431-4586-b516-3d7c1201291b" style="width:50%" class="column"><figure id="0e52fdf4-c1d7-4ff5-97fe-bac6c5662341" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2010.png"><img style="width:459px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2010.png"/></a></figure></div></div><p id="8ec3caf8-5bce-4c75-8410-9e54601d5ec6" class=""><strong><strong><strong><strong><strong><strong>Intensity values per channel</strong></strong></strong></strong></strong></strong><div class="indented"><ul id="8317bbf7-d6e4-4455-8a11-7372eb0e4990" class="bulleted-list"><li style="list-style-type:disc">If high intensity in all channels → white color</li></ul><ul id="0c79c82f-67e6-4070-9512-7cee642e6d82" class="bulleted-list"><li style="list-style-type:disc">If the color blue is brightest (in a blue object), then the blue channel will have the highest intensity</li></ul></div></p><p id="aee75f85-b24c-44ea-aa0f-fa8a80b1d4b3" class=""><strong><strong><strong><strong><strong><strong><strong><strong>Image is a </strong></strong></strong></strong></strong></strong></strong></strong><span style="border-bottom:0.05em solid"><span style="border-bottom:0.05em solid"><span style="border-bottom:0.05em solid"><span style="border-bottom:0.05em solid"><span style="border-bottom:0.05em solid"><span style="border-bottom:0.05em solid"><span style="border-bottom:0.05em solid"><span style="border-bottom:0.05em solid"><span style="border-bottom:0.05em solid"><span style="border-bottom:0.05em solid"><span style="border-bottom:0.05em solid"><span style="border-bottom:0.05em solid"><span style="border-bottom:0.05em solid"><span style="border-bottom:0.05em solid"><span style="border-bottom:0.05em solid"><span style="border-bottom:0.05em solid"><span style="border-bottom:0.05em solid"><span style="border-bottom:0.05em solid"><strong><strong><strong><strong><strong><strong><strong><strong>function from position.</strong></strong></strong></strong></strong></strong></strong></strong></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><strong><strong><strong><strong><strong><strong><strong><strong> </strong></strong></strong></strong></strong></strong></strong></strong>It defines the intensity of a position at x and y.</p><figure id="d382830d-8c46-49e7-a2ed-a5029a44c96a" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2011.png"><img style="width:705px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2011.png"/></a></figure><ul id="f5a29862-b2ce-4fab-9f81-c59c80ebb511" class="bulleted-list"><li style="list-style-type:disc">White areas → At the peaks (highest height)</li></ul><ul id="faa5931f-015f-45b5-9013-4b6f147f0665" class="bulleted-list"><li style="list-style-type:disc">Black areas → at the valleys (lowest height)</li></ul><p id="b6fb7ede-ae83-43a5-a192-76e53f4e0737" class="">Thus, <strong>intensity is a function of position x and y. </strong>The elevation shows how bright the image at this particular position is.</p><h2 id="75059e16-49a4-40ce-a10a-8be5241d714b" class="">Transformations</h2><div id="0e64064b-7464-4414-b418-2170c86e41cf" class="column-list"><div id="eaeffe24-076f-49e2-a8cb-6456ea4c8411" style="width:50%" class="column"><h3 id="95ea0451-7f97-4cdc-b745-5877427324c0" class="">Filtering</h3><figure id="4046e7c2-2e2e-4efe-932a-9aeae712133b" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>h</mi><mo stretchy="false">{</mo><mi>F</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">G(x) = h\{F(x)\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">h</span><span class="mopen">{</span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)}</span></span></span></span></span></div></figure><ul id="605864d1-f65e-4bde-92c0-5780c8dd826b" class="bulleted-list"><li style="list-style-type:disc">The operation is applied on F(x), the intensity function</li></ul><ul id="a07074af-af15-4e77-8017-570a6e2735b5" class="bulleted-list"><li style="list-style-type:disc">Changes pixel values</li></ul><ul id="37f2895f-f8f6-4a36-8527-deee3834088f" class="bulleted-list"><li style="list-style-type:disc">The intensity range is changed</li></ul></div><div id="737f9fcd-ed05-4152-8ea9-638ff2504cca" style="width:50%" class="column"><h3 id="66cb33db-ca3f-4a6f-a7e1-d4600a847c1c" class="">Warping</h3><figure id="61d7456f-4d7f-46f3-b376-069f0bd75ec2" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>G</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>F</mi><mo stretchy="false">(</mo><mi>h</mi><mo stretchy="false">{</mo><mi>x</mi><mo stretchy="false">}</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">G(x) = F(h\{x\})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class="mopen">(</span><span class="mord mathnormal">h</span><span class="mopen">{</span><span class="mord mathnormal">x</span><span class="mclose">})</span></span></span></span></span></div></figure><ul id="447fe771-3e78-40b1-9e95-c599be2b3a06" class="bulleted-list"><li style="list-style-type:disc">The operation is applied on the domain</li></ul><ul id="93b38320-f850-4202-8a0e-9b77b5f8d629" class="bulleted-list"><li style="list-style-type:disc">Changes pixel locations</li></ul><ul id="b2fd4600-1129-41fd-9353-244cf3506caa" class="bulleted-list"><li style="list-style-type:disc">The x and y domain are changed</li></ul><ul id="d84ac9e5-7c61-4921-8036-c3dbd4bd96ce" class="bulleted-list"><li style="list-style-type:disc">Dimensions can change</li></ul></div></div><figure id="c5704db5-87a7-4f46-b5ec-49548dc00de9" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2012.png"><img style="width:988px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2012.png"/></a></figure><div id="160017b0-fb10-4506-a95e-24b51ad2cdcd" class="column-list"><div id="e7a47ec5-0d15-4b0f-aa0d-560bf9da718a" style="width:50%" class="column"><h3 id="f6ae3c4e-eec3-49e9-8734-124884068cd2" class="">Point Operation</h3><ul id="b301b0d4-ff8c-449b-9670-83cfc0fd4dc9" class="bulleted-list"><li style="list-style-type:disc">Points that have the same value at the start will have the same value in the end</li></ul><figure id="c28fa31c-b310-41e4-a1f9-68cb133e7202" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2013.png"><img style="width:704px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2013.png"/></a></figure></div><div id="d416c3ff-b12c-483a-9b18-6a272a2e20e7" style="width:50%" class="column"><h3 id="b02801be-b3bc-47fa-9c98-b4257700b17f" class="">Filtering (Neighborhood Operation)</h3><ul id="9176028c-29fa-43c1-aa47-1aa4f7df56fc" class="bulleted-list"><li style="list-style-type:disc">Depends on the points’ neighbors not just the value of the point (depends on <span style="border-bottom:0.05em solid"><span style="border-bottom:0.05em solid">both</span></span>)</li></ul><figure id="c0fc2073-434e-4ce8-94e7-6bd93952a3c4" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2014.png"><img style="width:659px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2014.png"/></a></figure><p id="d006b451-60b7-4a2b-b54e-43c08c09c617" class="">
</p></div></div><figure class="block-color-brown_background callout" style="white-space:pre-wrap;display:flex" id="c2917983-354a-46df-9a38-09bd8fa905f6"><div style="font-size:1.5em"><span class="icon">👁️</span></div><div style="width:100%">Both are filtering processes</div></figure><h2 id="2e616c57-4066-4386-924a-b0e3e35f6135" class="">Point Processing </h2><figure id="8cf7bdc7-87b0-4bbc-ab76-df9e87598bb8" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2015.png"><img style="width:993px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2015.png"/></a></figure><ul id="45bdb2db-c8c2-4176-8428-0e6bbb4b4aea" class="bulleted-list"><li style="list-style-type:disc"><strong>darken </strong>→ subtract constant from each channel</li></ul><ul id="39ff5f20-3000-410b-b7f5-d76f3906ff3f" class="bulleted-list"><li style="list-style-type:disc"><strong><strong><strong><strong><strong><strong><strong><strong><strong>lighten → </strong></strong></strong></strong></strong></strong></strong></strong></strong>add constant to each channel</li></ul><ul id="6767a610-a87b-4736-8f75-1b019aa2ad86" class="bulleted-list"><li style="list-style-type:disc"><strong><strong><strong><strong><strong><strong>invert → </strong></strong></strong></strong></strong></strong>Maximum value - each value or 255 - each value</li></ul><figure class="block-color-brown_background callout" style="white-space:pre-wrap;display:flex" id="3df9727c-ec29-404d-88a3-f10d027b1bf3"><div style="font-size:1.5em"><span class="icon">👁️</span></div><div style="width:100%"><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Contrast: </strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>the difference between the maximum and the minimum intensities.<p id="75a49b62-1361-4611-a8c9-e5e0073edf4c" class=""> <strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Grey Level: </strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>each intensity value from 0 to 255 is called a grey level; totaling to 256 possible grey levels.</p><p id="66afead0-e0da-4c35-82b4-d208465519fb" class="">If not all grey levels are used and only values that are close to each other are used  (for example, just 16 levels from 0 to 15), then this is a low-contrast image. </p><p id="1e821c08-da2c-443b-aaf4-0529ce0d6ee6" class="">So, to increase contrast, we need to spread out the values over all of the 256 grey levels by scaling</p></div></figure><ul id="1f0d47c5-eb7c-4470-bdf5-1f06dee29f98" class="bulleted-list"><li style="list-style-type:disc"><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>raise contrast → </strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>multiply by a constant &gt; 1</li></ul><ul id="e7fe0e17-f216-4dcc-bf93-ee4edadecca3" class="bulleted-list"><li style="list-style-type:disc"><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>lower contrast → </strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>multiply by a constant &lt; 1</li></ul><ul id="26efbb72-9a55-4ba6-830c-3b5d7e6daee1" class="bulleted-list"><li style="list-style-type:disc"><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>non-linear raise contrast → </strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>raise to the power of a contrast</li></ul><ul id="54e4814b-b65f-4f3e-b327-6b38729ee46d" class="bulleted-list"><li style="list-style-type:disc"><strong><strong><strong><strong><strong>non-linear lower contrast → </strong></strong></strong></strong></strong>take the root </li></ul><p id="294689ba-30cf-4cd6-b4e3-e7aff81f5a66" class="">
</p><blockquote id="ca381b0f-c8dd-4bdd-afd9-534203fecde6" class=""><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Linear contrast enhancement</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong><p id="1ee6f879-2eb8-435f-8ec1-ee391a788720" class="">This type referred a contrast stretching, linearly expands the original digital values of the remotely sensed data into a new distribution. By expanding the original input values of the image, the total range of sensitivity of the display device can be utilized.</p><p id="29a34ff3-08d2-4262-a8e7-380538dcd7f4" class="">
</p><p id="9c919f39-6011-49d2-bda1-5de645351459" class=""><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Non-linear contrast enhancement</strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></p><p id="3ec0f5c3-9636-43e7-bf86-4d9430030450" class="">Nonlinear contrast enhancement often involves histogram equalizations through the use of an algorithm. The nonlinear contrast stretch method has one major disadvantage. Each value in the input image can have several values in the output image, so that objects in the original scene lose their correct relative brightness value.</p><p id="70bf9835-081b-41d7-98e7-3f8c4172abb0" class="">source: <a href="http://paper.ijcsns.org/07_book/201002/20100222.pdf">Mr. Salem Saleh Al-amri, Dr.N.V.Kalyankar, Dr.S.D.Khamitkar, “Linear and Non-linear Contrast Enhancement Image”</a></p></blockquote><figure class="block-color-brown_background callout" style="white-space:pre-wrap;display:flex" id="863756a1-bbc8-463a-b006-da52afa8900b"><div style="font-size:1.5em"><span class="icon">👁️</span></div><div style="width:100%"><mark class="highlight-red">Note</mark>: There is no circling or negative values in the range. If the value after processing exceeds 255 or is less than 0, the value is <em><em><em><em><em><em><em><em>clipped. </em></em></em></em></em></em></em></em>The operations may change the range so we must take special care to handle these cases.</div></figure><figure id="b3513440-a796-4d73-b4c8-356239a6380c" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2016.png"><img style="width:991px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2016.png"/></a></figure><h2 id="efb995a9-3bfe-49c8-a10e-ebc511986f45" class="">Linear shift-invariant image filtering</h2><ul id="3ef5a3f6-74c4-43dc-a739-9fa581b6c66c" class="bulleted-list"><li style="list-style-type:disc"><strong>Linear </strong>→ weighted sum. <strong>How?</strong><ul id="0eab704a-07e1-492d-b596-f8b5025b1db0" class="bulleted-list"><li style="list-style-type:circle"> <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mi>a</mi><mi>x</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">y = ax+b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">b</span></span></span></span></span><span>﻿</span></span> is a 1D linear equation.<style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext> </mtext><mi mathvariant="normal">Σ</mi><mtext> </mtext><msub><mi>a</mi><mi>i</mi></msub><msub><mi>x</mi><mi>i</mi></msub><mtext> </mtext></mrow><annotation encoding="application/x-tex"> \Sigma  a_{i} x_{i} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"> Σ </span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"> </span></span></span></span></span><span>﻿</span></span>is a general line equation with D dimensions. It is also the equation for weighted sum.</li></ul></li></ul><ul id="54df2006-e16f-47d0-8392-d858716258a4" class="bulleted-list"><li style="list-style-type:disc"><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Shift-invariant → </strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>the filter is the same regardless of its position</li></ul><ul id="ca4e2296-9f29-479a-aa9d-c721bdc066f3" class="bulleted-list"><li style="list-style-type:disc"><strong><strong><strong><strong><strong><strong><strong>Filtering → </strong></strong></strong></strong></strong></strong></strong>when filtering signals, we apply a function on the given signal. When we filter an image, a predefined filter function is similarly applied on all positions in the picture.</li></ul><blockquote id="c16c12b6-b7ac-4d8f-b0c9-1bf579666849" class="">Replace each pixel by a linear combination of its neighbors (and possibly itself). The combination is determined by the filter’s kernel. The same kernel is shifted to all pixel locations so that all pixels use the same linear combination of their neighbors.</blockquote><h3 id="cb6556d9-e6da-42e9-8638-d81a9c4c6c69" class="">Convolution and Correlation</h3><p id="9e7e047d-081f-41dc-9fe6-efff5b7f6aa4" class="">The convolution operation is a linear one. The filter defines the weighted sum and applies it on the entire image. The neighborhood is defined (what is included in the filter) and could be any shape (square, circular, etc).</p><figure id="dd32e691-7e28-4e2d-8e39-908275c394d7" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2017.png"><img style="width:624px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2017.png"/></a></figure><figure id="d0c23c51-19c3-44a8-869f-bb2585a43f3a" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2018.png"><img style="width:624px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2018.png"/></a><figcaption>Computer Vision: Algorithms and Applications, Richard Szeliski, Springer</figcaption></figure><figure id="2088e946-577b-494c-b2c7-7696b32d6ee1" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2019.png"><img style="width:1129px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2019.png"/></a></figure><p id="502ced3b-d651-4758-9b5e-0015c83e490d" class=""><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>How was this value computed? </strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>By in-place multiplication:</p><figure id="1d8834fe-952a-4413-aa90-26fa88aa70c8" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mn>65</mn><mo>×</mo><mn>0.1</mn><mo>+</mo><mn>98</mn><mo>×</mo><mn>0.1</mn><mo>+</mo><mn>123</mn><mo>×</mo><mn>0.1</mn><mspace linebreak="newline"></mspace><mo>+</mo><mn>65</mn><mo>×</mo><mn>0.1</mn><mo>+</mo><mn>96</mn><mo>×</mo><mn>0.2</mn><mo>+</mo><mn>115</mn><mo>×</mo><mn>0.1</mn><mspace linebreak="newline"></mspace><mo>+</mo><mn>63</mn><mo>×</mo><mn>0.1</mn><mo>+</mo><mn>91</mn><mo>×</mo><mn>0.1</mn><mo>+</mo><mn>107</mn><mo>×</mo><mn>0.1</mn><mspace linebreak="newline"></mspace><mo>=</mo><mn>92</mn></mrow><annotation encoding="application/x-tex">65\times0.1+98\times0.1+123\times0.1\newline+65\times0.1+96\times0.2+115\times0.1\newline+63\times0.1+91\times0.1+107\times0.1\newline=92</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">65</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0.1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">98</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0.1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">123</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0.1</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">+</span><span class="mord">65</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0.1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">96</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0.2</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">115</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0.1</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">+</span><span class="mord">63</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0.1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">91</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">0.1</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.72777em;vertical-align:-0.08333em;"></span><span class="mord">107</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">0.1</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0.36687em;vertical-align:0em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">92</span></span></span></span></span></div></figure><ul id="624191d4-7644-4ddb-ba97-e72f21b82322" class="bulleted-list"><li style="list-style-type:disc">Convolution → has flipping, the flipped version of normal filtering</li></ul><ul id="f9147f9e-24e7-4653-bf83-68c087fb8eb4" class="bulleted-list"><li style="list-style-type:disc">Correlation → no flipping</li></ul><figure id="68ff020a-f87e-428a-a42c-bf3ff5d0f631" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2020.png"><img style="width:985px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2020.png"/></a></figure><h3 id="3ab4eca5-df76-4dab-a534-89e66f1a7fa4" class="">Box Filter</h3><ul id="1f6cb63d-89d9-4fe4-9cc2-8d2f18e8fbd2" class="bulleted-list"><li style="list-style-type:disc">Also called 2D rect filter, square mean filter, or averaging filter.</li></ul><ul id="9495638f-8264-4d58-b376-d30cda4005ad" class="bulleted-list"><li style="list-style-type:disc">It replaces each pixel with the local average</li></ul><ul id="b778c624-229e-4404-b30b-3159c1e7c5ea" class="bulleted-list"><li style="list-style-type:disc">It gives a smoothing/blurring effect. <strong><strong><strong><strong>Why?</strong></strong></strong></strong><ul id="19b589d9-5b9e-475e-9e42-3cdebe28f05b" class="bulleted-list"><li style="list-style-type:circle">High frequencies (sudden change from one intensity value to another) are lost, so all pixels become closer in value to each other. </li></ul><ul id="da339b4a-58e2-4332-81a0-f600f438da76" class="bulleted-list"><li style="list-style-type:circle">It ends up losing very sharp edges, since in edges the difference between one pixel and its neighbor is large, giving it its sharpness.</li></ul></li></ul><ul id="51b14c5f-25b3-4185-bc8d-d7c25957bfea" class="bulleted-list"><li style="list-style-type:disc">It essentially acts as a low pass filter.<figure id="0cba874e-08bc-4d85-8131-e50b5bb09ec7" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/ezgif.com-gif-maker.gif"><img style="width:980px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/ezgif.com-gif-maker.gif"/></a></figure></li></ul><ul id="d721e36c-67d7-4dfc-9334-03ffd64722d8" class="bulleted-list"><li style="list-style-type:disc">It has the unwanted effect of pixelation, also called <strong>blocking effect.</strong> This is because of the filter’s box shape.</li></ul><figure id="5bb50219-9ed9-41da-a0cd-55947c83f9b8" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2021.png"><img style="width:971px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2021.png"/></a></figure><ul id="4aaef150-48bf-47db-b32a-9f4ae5bcb25d" class="bulleted-list"><li style="list-style-type:disc"><strong>Applications using box filters</strong>: template matching, which looks for all of the matching feature,. The filter looks like the template so that the dot product result  will be highest at the area that matches the template.</li></ul><p id="dbe89476-cddc-4166-b3b1-79f9c4b21689" class=""><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Why blur? </strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></p><ul id="9fa47f0a-5f24-4a40-956d-ad23709ad5cf" class="bulleted-list"><li style="list-style-type:disc">Noise, or <strong><strong><strong><strong><strong><strong>artifacts, </strong></strong></strong></strong></strong></strong>are outliers that have a very different value from its neighbors. It is an abrupt change in intensities, so by reducing the high frequencies we can remove the noise. However, we may also end up losing other features.</li></ul><ul id="db23023b-35c1-4874-aa6f-49961e29e17a" class="bulleted-list"><li style="list-style-type:disc"><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>High frequency </strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>is defined as high change between neighboring pixels.</li></ul><h2 id="eecc9465-cf78-4254-8af3-bb63f1111d7a" class="">Separable Filters</h2><figure id="6c08e8ab-cd7a-4a6f-a532-faef1640fac6" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2022.png"><img style="width:888px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2022.png"/></a></figure><h2 id="2c3bbb00-4462-42bd-9175-6b1f2173dde9" class="">The Gaussian Filter</h2><p id="3d0dfa5a-03f2-4b40-97f1-83417b00a254" class="">To avoid the box effect, we need to remove the sharp edge of the filter using <em><em><em><em><em><em><em><em><em><em><em><em><em><em><em><em><em>gradual fall-off. </em></em></em></em></em></em></em></em></em></em></em></em></em></em></em></em></em>We use the Gaussian function to find the values of our kernel.</p><figure id="b212ff56-cccf-4264-90ca-7cb26e019e2e" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2023.png"><img style="width:1241px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2023.png"/></a></figure><p id="003f4aaf-8cea-437b-866c-cfed579ab564" class=""><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span></span></span><span>﻿</span></span> represents the bandwidth. As it increases, spread of function increases. If <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span></span></span><span>﻿</span></span> is small, you don’t need many neighbors. This means you have a smaller window.</p><figure id="5b8ff70a-e542-4bc0-8cbb-c41bc1344802" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2024.png"><img style="width:500px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2024.png"/></a></figure><p id="0a45162d-2068-47ee-ac45-5a453f773cd3" class="">We typically use an integer approximation of the gaussian function at low <style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><span data-token-index="0" contenteditable="false" class="notion-text-equation-token" style="user-select:all;-webkit-user-select:all;-moz-user-select:all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi></mrow><annotation encoding="application/x-tex">\sigma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">σ</span></span></span></span></span><span>﻿</span></span>. This is because machines were not able to handle floating point operations, which is an operation burden.</p><h3 id="dbd6c75a-4227-46a3-8c21-baca8dfbed47" class="">Pascal’s Triangle </h3><figure id="dc552dc3-3b37-401b-ae52-921fe7ebff53" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2025.png"><img style="width:361px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2025.png"/></a></figure><p id="2f326cac-b59b-4a29-a686-05de252803e5" class="">This serves to approximate the weights so that they are integer. </p><div id="4b5844cc-18bb-496e-936e-2343089fd665" class="column-list"><div id="9120ea91-2b12-489c-bf49-82f97d9ad9fc" style="width:6.25%" class="column"><figure id="a7381d79-88f8-43a8-8b95-243dca676af3" class="equation"><style>@import url('https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css')</style><div class="equation-container"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mn>1</mn><mn>16</mn></mfrac></mrow><annotation encoding="application/x-tex"> \frac{1}{16} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.00744em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">16</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></div></figure></div><div id="c3a8d2da-a493-48a8-baee-f312e814aeb8" style="width:93.75%" class="column"><div id="44d51054-ccc9-45f4-ac65-20c4042a4ac0" class="column-list"><div id="49872c63-3261-4041-9165-e6728c7e4fa3" style="width:50%" class="column"><div id="8b216bd7-b74b-4f0f-8ab3-8edee04cea46" class="column-list"><div id="f9c4259c-9e6f-46a4-81cc-391270490cb4" style="width:56.25%" class="column"><table id="cf202a71-6fd3-4cd4-867f-3da97d27a67e" class="simple-table"><tbody><tr id="fccb6ab1-344b-4d17-9e97-a8cb16f21a0f"><td id="nP`C" class="" style="width:50px">1</td><td id="?=Cg" class="" style="width:52px">2</td><td id="RWxE" class="" style="width:41px">1</td></tr><tr id="bbc0021d-1782-4a4d-b04b-b5e8b1414f69"><td id="nP`C" class="" style="width:50px">2</td><td id="?=Cg" class="" style="width:52px">4</td><td id="RWxE" class="" style="width:41px">2</td></tr><tr id="5abb639a-c96e-4b22-a767-2409124b5455"><td id="nP`C" class="" style="width:50px">1</td><td id="?=Cg" class="" style="width:52px">2</td><td id="RWxE" class="" style="width:41px">1</td></tr></tbody></table></div><div id="52642bcc-b5af-4a81-bec1-a65843f74daa" style="width:43.75%" class="column"><p id="87dda2df-a31d-4626-b086-7803bdfd869b" class="">—→</p><p id="5cddeada-6dbd-4429-9c01-e29d52efc9de" class="">Separates into</p><p id="104c65ed-6bcf-4a1d-b160-28a9e039c795" class="">
</p></div></div><p id="64c48ecf-b444-4bda-805c-cbb446abb2b0" class="">Separable filter</p></div><div id="d7c094f7-3838-4e0c-9353-03744fd2194f" style="width:25%" class="column"><div id="8eaaf34d-b51d-4d4e-9b99-2fe07220f9f1" class="column-list"><div id="39bee266-dd2b-48d7-8fbe-4322b7cc6c80" style="width:50%" class="column"><table id="378b6808-dd6e-4703-aaf2-451eb1c4bd6b" class="simple-table"><tbody><tr id="c7e4fc66-8e24-43ac-8e9b-412aed68dc1c"><td id="fRSm" class="" style="width:38px">1</td></tr><tr id="3f0740b0-bcf2-4639-bc29-ab1565c152b5"><td id="fRSm" class="" style="width:38px">2</td></tr><tr id="05f5fdc0-00af-44cc-8cea-33c02c6f64b4"><td id="fRSm" class="" style="width:38px">1</td></tr></tbody></table></div><div id="d98a4d15-3a79-4488-9bd3-7fb314293c96" style="width:49.99999999999999%" class="column"><p id="b7a0b27d-2415-45b4-ad87-1445d25430a9" class="">* </p></div></div></div><div id="21f4216d-ea9f-41cb-b74d-2e0d7cc86061" style="width:25.00000000000002%" class="column"><table id="2d6f8c1f-fb60-4e19-8ba0-40e018a3be9b" class="simple-table"><tbody><tr id="9f59f3c7-77c0-4a29-ad43-0eefa20cf168"><td id="\&gt;qQ" class="" style="width:35px">1</td><td id="I}z;" class="" style="width:36px">2</td><td id="c`n[" class="" style="width:36px">1</td></tr></tbody></table><p id="0ce9ff0b-4fc3-4ff0-a3a1-9923f3853228" class="">
</p></div></div></div></div><p id="dc5eb442-69c0-4469-815f-c4f2b1ef0c23" class="">In fact: all gaussian filters are separable.</p><figure id="e25761c5-b3bf-43f6-915f-951482973445" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2026.png"><img style="width:995px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2026.png"/></a></figure><div id="98d2c156-7911-4c94-8660-787e3c9c9a7c" class="column-list"><div id="c870cc86-5612-4ba0-8abb-ccaa1001410f" style="width:50%" class="column"><figure id="02517bde-dd05-4548-8948-3304d7417008" class="image" style="text-align:left"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2027.png"><img style="width:480px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2027.png"/></a><figcaption>Soft shadow effect</figcaption></figure></div><div id="221064dd-9dee-45d3-b8b8-ed8ac0649261" style="width:50%" class="column"><figure id="d43c200a-d0c9-4b75-920e-74129b4ce189" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2028.png"><img style="width:542px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2028.png"/></a><figcaption>Identity filter</figcaption></figure></div></div><div id="bf5f4722-e142-4d74-bf6e-d56b89a011da" class="column-list"><div id="5fbca4e8-f4af-47ed-aa54-c8896070a544" style="width:50%" class="column"><figure id="504eace1-f6af-4290-86dc-a182d11fabf5" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2029.png"><img style="width:552px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2029.png"/></a><figcaption>Shifting filter</figcaption></figure></div><div id="b7955022-9c97-41eb-8d2b-a9481e59d884" style="width:50%" class="column"><figure id="d55385b4-0856-4e41-aa19-69653b02d044" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2030.png"><img style="width:551px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2030.png"/></a><figcaption>Sharpening filter</figcaption></figure></div></div><p id="749b8cd3-21b5-4c45-8013-54bccb3e33b1" class=""><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>Sharpening filter: </strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>ensures that if two neighboring values are the same or near each other, nothing is changed. We scale the kernel so that no output values exceed the range.</p><p id="66ac81fd-eb12-452a-8217-f0ee7ca2627b" class=""><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong><strong>What happens if we oversharpen? </strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong></strong>We introduce artifacts (increase noise).</p><figure id="68957661-7777-427a-aa55-2b5330e01c34" class="image"><a href="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2031.png"><img style="width:833px" src="Computer%20Vision%20Lecture%201%20bb8f13146ebd4a32bc6d9fb4fc6c8bce/Untitled%2031.png"/></a></figure></div></article></body></html>